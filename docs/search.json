[
  {
    "objectID": "CAH-Cours.html#objectifs-dapprentissage",
    "href": "CAH-Cours.html#objectifs-dapprentissage",
    "title": "Introduction à la classification",
    "section": "OBJECTIFS D’APPRENTISSAGE",
    "text": "OBJECTIFS D’APPRENTISSAGE\n\nComprendre la nature générale d’une procédure de classification non supervisée\nConstruire une matrice de dissimilarité à partir d’un tableau à 1, 2 ou k dimension\nConstruire une classification ascendante hiérarchique à l’aide du critère de Ward\nComprendre le lien entre ACP et CAH"
  },
  {
    "objectID": "CAH-Cours.html#introduction",
    "href": "CAH-Cours.html#introduction",
    "title": "Introduction à la classification",
    "section": "Introduction",
    "text": "Introduction\nLa classification consiste d’une manière générale à regrouper dans une même classe des individus qui se ressemblent et à séparer dans des classes différentes ceux qui sont différents. Ce problème très général est au coeur même de toute démarche scientifique et il soulève des questions épistémologiques et philosophiques fondamentales qui dépassent le cadre de cet enseignement. Nous nous limiterons ici à poser le problème de la classification dans le cadre de procédures statistiques appliquées à des variables de type quantitatif continu. Nous montrerons que le problème posé est alors celui de la recherche d’une classification non supervisée c’est-à-dire la découverte de ressemblances entre des individus en fonction de critères objectivement reproductibles."
  },
  {
    "objectID": "CAH-Cours.html#classification-dans-un-espace-à-une-dimension",
    "href": "CAH-Cours.html#classification-dans-un-espace-à-une-dimension",
    "title": "Introduction à la classification",
    "section": "Classification dans un espace à une dimension",
    "text": "Classification dans un espace à une dimension\nConsidérons à titre de premier exemple la consommation moyenne d’alcool (mesurée en kCal/pers/j) de 9 régions d’Europe et d’Afrique\n\n\n\n\nExemple 1 : variable unique \n \n  \n      \n    region \n    Alcool \n  \n \n\n  \n    1 \n    Afrique australe \n    101 \n  \n  \n    2 \n    Afrique centrale \n    39 \n  \n  \n    3 \n    Afrique occidentale \n    21 \n  \n  \n    4 \n    Afrique orientale \n    35 \n  \n  \n    5 \n    Afrique septentrionale \n    4 \n  \n  \n    6 \n    Europe méridionale \n    145 \n  \n  \n    7 \n    Europe occidentale \n    176 \n  \n  \n    8 \n    Europe orientale \n    160 \n  \n  \n    9 \n    Europe septentrionale \n    146 \n  \n\n\n\n\n\nEssayons de répondre à des questions d’abord à des questions simples comme :\n\nQ1 : quelles sont les deux régions les plus dissemblantes ?\nQ2 :l’Afrique Occidentale ressemble-t-elle plus à l’Afrique septentrionale ou à l’Afrique Australe ?\n\nPuis à des questions plus complexes comme :\n\nQ3 : Quelle est la meilleure partition en deux classes ?\nQ4 : Quelle est la meilleure partition en k classes ?\nLa question Q1 est la plus simple et sa réponse ne devrait pas susciter de débat. sachant que la valeur miniumum est de 4 et la valeur maximale de 176, on peut conclure que la plus grande différence est observée entre l’Afrique septentrionale (point n°5) et l’Europe occidentale (point n°7). On peut visualiser leuer éloignement à l’aide d’une figure :\n\n\n\n\n\n\n\nLa question Q2 est en revanche moins simple qu’il n’y paraît car elle peut appeler des réponses différentes selon que l’on décide d’utiliser des différences absolues ou des différences relatives entre les régions.\n\n\nDistance absolue\nSi l’on raisonne en valeur absolue, nous allons construire une matrice de dissimilarité \\(D_{abs}\\) définie par :\n\\(D_{abs}(i,j) = \\lvert{X_i-X_j}\\rvert\\)\n\n\n\n\nMatrice des différences absolues\n \n  \n      \n    1 \n    2 \n    3 \n    4 \n    5 \n    6 \n    7 \n    8 \n    9 \n  \n \n\n  \n    1. Afrique australe \n    0 \n    62 \n    80 \n    66 \n    97 \n    44 \n    75 \n    59 \n    45 \n  \n  \n    2. Afrique centrale \n    62 \n    0 \n    18 \n    4 \n    35 \n    106 \n    137 \n    121 \n    107 \n  \n  \n    3. Afrique occidentale \n    80 \n    18 \n    0 \n    14 \n    17 \n    124 \n    155 \n    139 \n    125 \n  \n  \n    4. Afrique orientale \n    66 \n    4 \n    14 \n    0 \n    31 \n    110 \n    141 \n    125 \n    111 \n  \n  \n    5. Afrique septentrionale \n    97 \n    35 \n    17 \n    31 \n    0 \n    141 \n    172 \n    156 \n    142 \n  \n  \n    6. Europe méridionale \n    44 \n    106 \n    124 \n    110 \n    141 \n    0 \n    31 \n    15 \n    1 \n  \n  \n    7. Europe occidentale \n    75 \n    137 \n    155 \n    141 \n    172 \n    31 \n    0 \n    16 \n    30 \n  \n  \n    8. Europe orientale \n    59 \n    121 \n    139 \n    125 \n    156 \n    15 \n    16 \n    0 \n    14 \n  \n  \n    9. Europe septentrionale \n    45 \n    107 \n    125 \n    111 \n    142 \n    1 \n    30 \n    14 \n    0 \n  \n\n\n\n\n\nOn serait alors tenté de dire que l’Afrique occidentale ressemble plus à l’Afrique septentrionale qu’à l’Afrique Australe puisque les distances observées sont de 17 dans le premier cas et de 80 dans le second.\n\n\nDistance relative\nMais on pourrait aussi considérer la distance relative en effectuant pour chaque paire de valeur le rapport entre le maximum et le maximum. Soit la matrice de distance relative \\(D_{rel}\\) définie par :\n\\(D_{rel}(i,j) = \\frac{max(X_i,X_j)}{min(X_i,X_j)}\\)\n\n\n\n\nMatrice des différences relatives\n \n  \n      \n    1 \n    2 \n    3 \n    4 \n    5 \n    6 \n    7 \n    8 \n    9 \n  \n \n\n  \n    1. Afrique australe \n    1.00 \n    2.59 \n    4.81 \n    2.89 \n    25.25 \n    1.44 \n    1.74 \n    1.58 \n    1.45 \n  \n  \n    2. Afrique centrale \n    2.59 \n    1.00 \n    1.86 \n    1.11 \n    9.75 \n    3.72 \n    4.51 \n    4.10 \n    3.74 \n  \n  \n    3. Afrique occidentale \n    4.81 \n    1.86 \n    1.00 \n    1.67 \n    5.25 \n    6.90 \n    8.38 \n    7.62 \n    6.95 \n  \n  \n    4. Afrique orientale \n    2.89 \n    1.11 \n    1.67 \n    1.00 \n    8.75 \n    4.14 \n    5.03 \n    4.57 \n    4.17 \n  \n  \n    5. Afrique septentrionale \n    25.25 \n    9.75 \n    5.25 \n    8.75 \n    1.00 \n    36.25 \n    44.00 \n    40.00 \n    36.50 \n  \n  \n    6. Europe méridionale \n    1.44 \n    3.72 \n    6.90 \n    4.14 \n    36.25 \n    1.00 \n    1.21 \n    1.10 \n    1.01 \n  \n  \n    7. Europe occidentale \n    1.74 \n    4.51 \n    8.38 \n    5.03 \n    44.00 \n    1.21 \n    1.00 \n    1.10 \n    1.21 \n  \n  \n    8. Europe orientale \n    1.58 \n    4.10 \n    7.62 \n    4.57 \n    40.00 \n    1.10 \n    1.10 \n    1.00 \n    1.10 \n  \n  \n    9. Europe septentrionale \n    1.45 \n    3.74 \n    6.95 \n    4.17 \n    36.50 \n    1.01 \n    1.21 \n    1.10 \n    1.00 \n  \n\n\n\n\n\nOn aboutit désormais à une conclusion inverse. En effet le rapport de consommation d’alcool est de 1 à 4.81 dans le cas de l’Afrique australe et de 1 à 5.25 dans le cas del’Afrique septentrionale.\n\n\nDistance logarithmique\nOn aurait pu aboutir à la même conclusion en calculant les différences absolues entre les logarithmes des valeurs respectives de Xi et Xj soit la matrice \\(D_{log}\\) :\n\\(D_{log}(i,j) = \\lvert{log(X_i)-log(X_j)}\\rvert\\)\n\n\n\n\nMatrice des différences logarithmiques\n \n  \n      \n    1 \n    2 \n    3 \n    4 \n    5 \n    6 \n    7 \n    8 \n    9 \n  \n \n\n  \n    1. Afrique australe \n    0.00 \n    0.95 \n    1.57 \n    1.06 \n    3.23 \n    0.36 \n    0.56 \n    0.46 \n    0.37 \n  \n  \n    2. Afrique centrale \n    0.95 \n    0.00 \n    0.62 \n    0.11 \n    2.28 \n    1.31 \n    1.51 \n    1.41 \n    1.32 \n  \n  \n    3. Afrique occidentale \n    1.57 \n    0.62 \n    0.00 \n    0.51 \n    1.66 \n    1.93 \n    2.13 \n    2.03 \n    1.94 \n  \n  \n    4. Afrique orientale \n    1.06 \n    0.11 \n    0.51 \n    0.00 \n    2.17 \n    1.42 \n    1.62 \n    1.52 \n    1.43 \n  \n  \n    5. Afrique septentrionale \n    3.23 \n    2.28 \n    1.66 \n    2.17 \n    0.00 \n    3.59 \n    3.78 \n    3.69 \n    3.60 \n  \n  \n    6. Europe méridionale \n    0.36 \n    1.31 \n    1.93 \n    1.42 \n    3.59 \n    0.00 \n    0.19 \n    0.10 \n    0.01 \n  \n  \n    7. Europe occidentale \n    0.56 \n    1.51 \n    2.13 \n    1.62 \n    3.78 \n    0.19 \n    0.00 \n    0.10 \n    0.19 \n  \n  \n    8. Europe orientale \n    0.46 \n    1.41 \n    2.03 \n    1.52 \n    3.69 \n    0.10 \n    0.10 \n    0.00 \n    0.09 \n  \n  \n    9. Europe septentrionale \n    0.37 \n    1.32 \n    1.94 \n    1.43 \n    3.60 \n    0.01 \n    0.19 \n    0.09 \n    0.00 \n  \n\n\n\n\n\nCe résultat est logique si on se rappelle que :\n\\(log(\\frac{X_i}{X_j}) = log(X_i) - log(X_j)\\)\nLes valeurs affichées dans cette troisième matrice ne sont donc rien d’autre que les logarithmes des valeurs de la seconde matrice.\n\n\nDistance euclidienne (au carré)\nPrésentons pour finir une quatrième matrice de distance correspondant au carré des différences entre les valeurs que nous nommerons distance euclidienne au carré :\n\\(D_{euc}^2(i,j) = (X_i-X_j)^2\\)\n\n\n\n\nMatrice des différences euclidiennes au carré\n \n  \n      \n    1 \n    2 \n    3 \n    4 \n    5 \n    6 \n    7 \n    8 \n    9 \n  \n \n\n  \n    1. Afrique australe \n    0 \n    3844 \n    6400 \n    4356 \n    9409 \n    1936 \n    5625 \n    3481 \n    2025 \n  \n  \n    2. Afrique centrale \n    3844 \n    0 \n    324 \n    16 \n    1225 \n    11236 \n    18769 \n    14641 \n    11449 \n  \n  \n    3. Afrique occidentale \n    6400 \n    324 \n    0 \n    196 \n    289 \n    15376 \n    24025 \n    19321 \n    15625 \n  \n  \n    4. Afrique orientale \n    4356 \n    16 \n    196 \n    0 \n    961 \n    12100 \n    19881 \n    15625 \n    12321 \n  \n  \n    5. Afrique septentrionale \n    9409 \n    1225 \n    289 \n    961 \n    0 \n    19881 \n    29584 \n    24336 \n    20164 \n  \n  \n    6. Europe méridionale \n    1936 \n    11236 \n    15376 \n    12100 \n    19881 \n    0 \n    961 \n    225 \n    1 \n  \n  \n    7. Europe occidentale \n    5625 \n    18769 \n    24025 \n    19881 \n    29584 \n    961 \n    0 \n    256 \n    900 \n  \n  \n    8. Europe orientale \n    3481 \n    14641 \n    19321 \n    15625 \n    24336 \n    225 \n    256 \n    0 \n    196 \n  \n  \n    9. Europe septentrionale \n    2025 \n    11449 \n    15625 \n    12321 \n    20164 \n    1 \n    900 \n    196 \n    0 \n  \n\n\n\n\n\nA première vue cette quatrième mesure de dissimilarité n’a pas grand intérêt puisqu’elle ne fait que reprendre les distances absolues en renforçant leur effet. La distance entre Afrique occidentale et Afrique australe est désormais de \\(80^2 = 6400\\) tandis que celle entre Afrique occidentale et Afrique septentrionale est de \\(17^2 = 289\\).\nEn réalité, cette dernière mesure de distance est l’une des plus utilisée dans les méthodes de classification car elle permet d’établir un lien entre la notion de dissimilarité et la notion de variance. La somme de la matrice des distances euclidiennes au carré est en effet proportionelle à la variance de la variable X puisque :\n\\({var}(X) = \\frac{1}{n-1}\\sum_{i=1}^n{(X_i-\\overline{X})^2} = \\frac{1}{2.n.(n-1)}\\sum_{i=1}^n\\sum_{j=1}^n{(X_i-X_j)^2}\\)\nCe que l’on peut vérifier facilement en calculant la variance de notre indicateur (4541.111) et en la comparant au total de la matrice des distances euclidiennes au carré (653920). Puis en effectuant le calcul \\(4541.111 \\times 9 \\times 8 \\times 2 = 653920\\)\n\n\nPartition optimale en deux classes\nLa recherche d’une partition optimale en deux classes dans un espace à une dimension est relativement simple mais elle impose de se fixer une règle précise de décision, c’est-à-dire un critère de performance à optimiser. D’une manière générale, ce critère devra répondre à la défintion proposée en introduction à savoir :\n\nregrouper les unités qui se ressemblent le plus entre elles\nséparer les unités qui sont les plus différentes entre elles.\n\nAu vu de la distribution de notre variable, il semble assez évident que nous allons regrouper ensemble les quatres régions d’Europe (n°6,7,8,9) à forte consommation d’alcool et les quatre régions d’Afrique (n°2,3,4,5) à faible consommation. Mais on peut hésiter sur l’affectation de la région n°1 qui se situe à peu près à mi-chemin entre les deux groupes. Faut-il couper en A (trait rouge) ou en B (trait bleu) ?\n\n\n\n\n\nUne manière statistique de trancher entre les deux solutions consiste à utiliser l’analyse de variance et de tester la part de variance expliquée par un modèle rattachant le point central soit à l’Europe (on coupe en A), soit à l’Afrique (on coupe en B). On construit donc le tableau suivant :\n\n\n\n\n \n  \n    region \n    Alcool \n    Classes_2A \n    Classes_2B \n  \n \n\n  \n    Afrique australe \n    101 \n    CL2 \n    CL1 \n  \n  \n    Afrique centrale \n    39 \n    CL1 \n    CL1 \n  \n  \n    Afrique occidentale \n    21 \n    CL1 \n    CL1 \n  \n  \n    Afrique orientale \n    35 \n    CL1 \n    CL1 \n  \n  \n    Afrique septentrionale \n    4 \n    CL1 \n    CL1 \n  \n  \n    Europe méridionale \n    145 \n    CL2 \n    CL2 \n  \n  \n    Europe occidentale \n    176 \n    CL2 \n    CL2 \n  \n  \n    Europe orientale \n    160 \n    CL2 \n    CL2 \n  \n  \n    Europe septentrionale \n    146 \n    CL2 \n    CL2 \n  \n\n\n\n\n\n\n\n\nCall:\nlm(formula = don$Alcool ~ don$Classes_2A)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-44.60  -3.75   0.40  14.25  30.40 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          24.75      11.76   2.104  0.07342 .  \ndon$Classes_2ACL2   120.85      15.78   7.658  0.00012 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.52 on 7 degrees of freedom\nMultiple R-squared:  0.8934,    Adjusted R-squared:  0.8781 \nF-statistic: 58.64 on 1 and 7 DF,  p-value: 0.0001204\n\n\nAnalysis of Variance Table\n\nResponse: don$Alcool\n               Df Sum Sq Mean Sq F value    Pr(>F)    \ndon$Classes_2A  1  32455   32455  58.644 0.0001204 ***\nResiduals       7   3874     553                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCall:\nlm(formula = don$Alcool ~ don$Classes_2B)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-36.00 -11.75  -5.00   3.25  61.00 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          40.00      13.14   3.045 0.018708 *  \ndon$Classes_2BCL2   116.75      19.70   5.926 0.000584 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 29.37 on 7 degrees of freedom\nMultiple R-squared:  0.8338,    Adjusted R-squared:   0.81 \nF-statistic: 35.11 on 1 and 7 DF,  p-value: 0.0005843\n\n\nAnalysis of Variance Table\n\nResponse: don$Alcool\n               Df  Sum Sq Mean Sq F value    Pr(>F)    \ndon$Classes_2B  1 30290.1 30290.1  35.112 0.0005843 ***\nResiduals       7  6038.8   862.7                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nL’analyse des résultats montre que la solution A est la meilleure dans la mesure où elle a boutit à 89.4% de variance expliquée (donc interclasse) et 10.6% de variance résiduelle (donc intraclasse). La solution B n’arrive qu’à 83.4% de variance interclasse contre 16.6% de variance intraclasse.\nIl semble donc plus intéressant de regrouper l’Afrique australe avec les pays européens si le critère à optimiser est la variance c’est-à-dire la somme des distances euclidiennes élevées au carré. Les conclusion auraient évidemment pu être différentes si nous avions adopté un autre critère.\n\n\nPartition optimale en k-classes\nSupposons maintenant que nous cherchions à diviser notre variable en quatre classes, quelle serait la solution optimale en conservant le critère précédent de minimisation de la variance intra-classe et de maximisation de la variance inter-classe ?\nLe problème posé est d’une grande complexité mathématique lorsqu’il s’applique à de grand tableaux de données. On utilise le plus souvent des algorithmes comme celui de Jenks pour trouver la meilleure solution possible. Parmi les méthodes facilement accessibles dans R-base pour des tableaux de petite taille, ont peut souligner l’intérêt de la méthode des noyaux mobiles qui consiste à tirer au hasard plusieurs centres de classes et à regrouper autour d’eux les éléments les plus proches jusqu’à atteindre une convergence. En répétant les tirages à sort, on peut espérer se rapprocher de la solution optimale.\nDans notre exemple, on active la procédure k-means pour 100 tirages au sort :\n\n\n\n\n \n  \n      \n    region \n    Alcool \n    Classes_2A \n    Classes_2B \n    Classes_4 \n  \n \n\n  \n    5 \n    Afrique septentrionale \n    4 \n    CL1 \n    CL1 \n    CL1 \n  \n  \n    3 \n    Afrique occidentale \n    21 \n    CL1 \n    CL1 \n    CL1 \n  \n  \n    4 \n    Afrique orientale \n    35 \n    CL1 \n    CL1 \n    CL3 \n  \n  \n    2 \n    Afrique centrale \n    39 \n    CL1 \n    CL1 \n    CL3 \n  \n  \n    1 \n    Afrique australe \n    101 \n    CL2 \n    CL1 \n    CL4 \n  \n  \n    6 \n    Europe méridionale \n    145 \n    CL2 \n    CL2 \n    CL2 \n  \n  \n    9 \n    Europe septentrionale \n    146 \n    CL2 \n    CL2 \n    CL2 \n  \n  \n    8 \n    Europe orientale \n    160 \n    CL2 \n    CL2 \n    CL2 \n  \n  \n    7 \n    Europe occidentale \n    176 \n    CL2 \n    CL2 \n    CL2 \n  \n\n\n\n\n\nLa solution trouvée par l’algorithme consiste à séparer la région d’Afrique Australe de l’Europe pour en faire une classe à elle toute seule. Puis à diviser les 4 régions d’Afrique en deux paires."
  },
  {
    "objectID": "CAH-Cours.html#classification-dans-un-espace-à-2-dimensions",
    "href": "CAH-Cours.html#classification-dans-un-espace-à-2-dimensions",
    "title": "Introduction à la classification",
    "section": "Classification dans un espace à 2 dimensions",
    "text": "Classification dans un espace à 2 dimensions"
  },
  {
    "objectID": "CAH-Cours.html#bibliographie",
    "href": "CAH-Cours.html#bibliographie",
    "title": "Introduction à la classification",
    "section": "Bibliographie",
    "text": "Bibliographie"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "EXP3 : Stat. Multivariée",
    "section": "",
    "text": "…"
  },
  {
    "objectID": "ACP-Cours.html#objectifs-dapprentissage",
    "href": "ACP-Cours.html#objectifs-dapprentissage",
    "title": "Introduction à l’ACP",
    "section": "OBJECTIFS D’APPRENTISSAGE",
    "text": "OBJECTIFS D’APPRENTISSAGE\n\nComprendre la nature de l’analyse en composantes principales et son utilité pratique\nsavoir exécuter et interpréter une analyse de composants dans R en utilisant les fonctions R-base prcomp() et princomp().\nsavoir tracer des matrices de corrélation entre les variables pour évaluer l’ampleur de leur redondance.\nSavoir donner un sens concret aux facteurs dérivés de l’ACP."
  },
  {
    "objectID": "ACP-Cours.html#introduction",
    "href": "ACP-Cours.html#introduction",
    "title": "Introduction à l’ACP",
    "section": "Introduction",
    "text": "Introduction\n\nN.B. Cette introduction est directement adaptée du chapitre 10 de Denis (2020), pp. \n\nL’analyse en composantes principales, ou « ACP » en abrégé, est une technique de réduction des données utilisée pour transformer la variance d’un ensemble de p variables en moins de p dimensions. L’ACP traditionnelle suppose que les variables sont de nature quantitative continue.\nPar exemple, supposons qu’un chercheur ait 100 variables dans son ensemble de données. Dans ces variables il y a une certaine quantité de variance. En d’autres termes, l’ensemble complet de variables contient une quantité particulière de variabilité qui constitue l’information contenue dans ces variables (s’il n’y avait pas de variabilité, il n’y aurait pas d’information !). Si nous voulions connaître la variance totale des variables, nous pourrions les additionner et obtenir une mesure de la variance totale.\nCe que l’ACP cherche à faire, c’est de prendre cet ensemble original de variables dans p dimensions et d’effectuer une transformation sur ces variables de telle sorte que la quantité totale de variance d’origine soit préservée. Par exemple, si nous avons 100 variables représentant une variance totale de 500, la transformation opérée par l’ACP ne modifiera pas cette quantité totale de variance. Ce qu’elle va faire, c’est tenter d’expliquer cette variance avec le moins de nouvelles «composantes» possible, de sorte que les premières composantes extraites expliqueront la majeure partie de la variance dans l’ensemble initial de variables. C’est du moins l’espoir, si la technique réussit…\nL’objectif est donc de réussir à résumer la majeure partie de la variance à l’aide des premières composantes (aussi appelées facteurs) et donc de “réduire les données” à ces quelques facteurs. Au lieu d’avoir besoin d’étudier toutes les variables initiales, le chercheur pourra alors se concentrer sur l’analyse des premiers facteurs qui expliquent la majeure partie de la variance des variables. Considérez à titre d’exemple la figure tirée de Denis (2021).\n\n\n\n\n\nDans le graphique, les axes d’origine sont A1 et A2. Les “nouveaux” axes après la transformation sont E1 et E2. Bien qu’il existe plusieurs façons d’interpréter le fonctionnement de l’ACP, une méthode courante consiste à visualiser les composants de l’échantillon comme générés en faisant pivoter les axes de coordonnées afin qu’ils traversent la dispersion dans le tracé de la variance maximale (Johnson and Wichern (2007)).\nPar conséquent, nous pouvons voir que l’ACP a effectué une rotation telle que les nouveaux axes optimisent certaines fonctions des données. Quelle fonction est maximisée ? Comme nous le verrons, la rotation se produit de telle sorte que la première composante représente autant de variance que possible dans les variables d’origine, tandis que la seconde composante rend compte autant que possible de la variance des variables d’origine, mais sous réserve du fait qu’elle est orthogonale à la première composante. Remarquez que sur la figure, les axes sont perpendiculaires les uns aux autres, ce qui revient à dire qu’ils sont à 90°. C’est la condition d’orthogonalité."
  },
  {
    "objectID": "ACP-Cours.html#principes-de-lacp",
    "href": "ACP-Cours.html#principes-de-lacp",
    "title": "Introduction à l’ACP",
    "section": "PRINCIPES DE L’ACP",
    "text": "PRINCIPES DE L’ACP\n\nN.B. Cette section est directement adaptée du chapitre 10 de Denis (2020) mais en modifiant l’exemple retenu par l’auteur\n\nL’ACP est généralement appliquée à des ensembles de données qui contiennent de nombreuses variables, parfois des centaines, puisque c’est surtout pour ces ensembles de données que l’on souhaite réduire la dimensionnalité. Par exemple, si notre ensemble de données contient 1000 variables, l’ACP peut être utile pour réduire la dimensionnalité à 2 ou 3 dimensions (si la procédure a réussi). De cette façon, des données comme celle-ci font de l’ACP une approche analytique potentiellement appropriée en raison des nombreuses variables ou dimensions avec lesquelles nous commençons. D’autres fois, nous souhaitons effectuer une ACP sur des ensembles de données avec un plus petit nombre de variables, par exemple, 5-10, pour voir si nous pouvons également réduire ou découvrir la dimensionnalité des données.Quel que soit le nombre de variables avec lesquelles vous commencez, l’ACP peut être une technique appropriée pour vos données.\nCependant, pour comprendre l’ACP à partir des premiers principes, il est très utile et pédagogique de commencer par un exemple très simple ne comportant que deux variables. Pourquoi commencer par un exemple avec seulement deux variables ? Nous le faisons parce que cela permet d’apprécier un peu plus ce que fait l’ACP au lieu de se perdre dans un exemple plus complexe où nous pourrions ne pas apprécier ses mécanismes sous-jacents. Une fois que nous aurons apprécié le fonctionnement de l’ACP sur un petit échantillon , nous serons en mesure de considérer des ensembles de données beaucoup plus complexes permettant d’apprécier toute la puissance de la méthode.\n\nLes consommations de lait et de vin\nNous considérons un tableau issu des données de la FAO composé de 2 variables décrivant 9 individus décrivant la consommation de lait et de vin dans la ration alimentaire quotidienne des habitants des régions d’Europe et d’Afrique. Précisons que ces valeurs sont des estimations tirées d’enquêtes et d’extrapolations et non pas de mesures directes.\n\n\n\n\n\n\n\nConsommation moyenne de lait et d'alcool en Europe et en Afrique en 2020 (en kCal/pers/jour)\n \n  \n      \n    region \n    Alcool \n    Lait \n  \n \n\n  \n    AFR_Sud \n    Afrique australe \n    101 \n    90 \n  \n  \n    AFR_Centre \n    Afrique centrale \n    39 \n    12 \n  \n  \n    AFR_Ouest \n    Afrique occidentale \n    21 \n    26 \n  \n  \n    AFR_Est \n    Afrique orientale \n    35 \n    71 \n  \n  \n    AFR_Nord \n    Afrique septentrionale \n    4 \n    134 \n  \n  \n    EUR_Sud \n    Europe méridionale \n    145 \n    310 \n  \n  \n    EUR_Ouest \n    Europe occidentale \n    176 \n    446 \n  \n  \n    EUR_Est \n    Europe orientale \n    160 \n    290 \n  \n  \n    EUR_Nord \n    Europe septentrionale \n    146 \n    380 \n  \n\n\n\n\n\nPour gagner en abstraction, nous désignerons par la suite les variables sous la simple forme \\(X\\) et \\(Y\\) et nous donnerons aux individus qui les composent un simple identifiant numérique correspondant à leur numéro de ligne : \\(1...9\\). Nous obtenons ainsi un tableau que l’on appellera acp.data et qui est de type data.frame:\n\nX<-don$Alcool\nY<-don$Lait\nacp.data<-data.frame(X,Y)\nkable(acp.data, caption = \"Données\")\n\n\n\nDonnées\n \n  \n    X \n    Y \n  \n \n\n  \n    101 \n    90 \n  \n  \n    39 \n    12 \n  \n  \n    21 \n    26 \n  \n  \n    35 \n    71 \n  \n  \n    4 \n    134 \n  \n  \n    145 \n    310 \n  \n  \n    176 \n    446 \n  \n  \n    160 \n    290 \n  \n  \n    146 \n    380 \n  \n\n\n\n\n\nOn peut commencer par le visualiser avec la fonction plot()\n\nplot(acp.data, asp=1)\n\n\n\n\nNos données ayant deux dimensions, X et Y, la question posée par l’ACP est la suivante :\n\nPouvons nous transformer ce tableau de données à deux dimension (X et Y) en un autre tableau à deux dimensions (F1 et F2) de telle sorte que F1 concentre la plus grande part possible de la variance du tableau initial ?\n\nL’ACP opère donc une transformation sur les variables, avec l’espoir que la première dimension représentera la majeure partie de la variance totale d’origine. Mais cela ne signifie pas pour autant que l’on réduit - dans un premier temps - le nombre de dimensions. Dans la transformation, l’ACP générera généralement autant de dimensions qu’il y a de variables d’origine dans le tableau de données.\nL’ACP se donne simplement pour objectif que la majeure partie de la variance des variables d’origine sera expliquée par la première dimension - dans notre exemple - ou par les deux ou trois premières dans un tableau comportant davantage de variables. Si nous avions un tableau avec 100 variables, nous aurions également voulu les transformer en 100 nouvelles dimensions, dans l’espoir que la majeure partie de la variance des dimensions d’origine (variables) puisse être expliquée par les quelques premières composantes. C’est la nature de l’APC.\nEn ce sens, l’ACP n’est donc rien de plus qu’une transformation des axes d’origine vers de nouvelles dimensions. Les caractéristiques de ces nouvelles dimensions (composantes) et le nombre d’entre elles que nous pouvons choisir de conserver est un autre problème (que nous discuterons sous peu).\nPour effectuer l’ACP, nous avons d’abord besoin de quelque chose pour représenter comment les variables \\(X\\) et \\(Y\\) covarient ensemble. Pour cela, nous allons construire la matrice de covariance de \\(X\\) et \\(Y\\). Dans R, nous pouvons construire cette matrice sous la forme d’un objet nommé \\(A\\) à l’aide de la fonction cov() appliquée à l’ensemble du tableau de données.\n\nA <- cov(acp.data)\nA\n\n         X         Y\nX 4541.111  9602.306\nY 9602.306 26455.778\n\n\nRappelons la nature d’une matrice de covariance : Ellel contient les variances des variables le long de la diagonale principale allant du haut à gauche vers le bas droite. Pour nos données, la variance de \\(X\\) est égale à 26455.778 et la variance de \\(Y\\) est égale à 4541.111 . Les covariances entre \\(X\\) et \\(Y\\) sont données par les cases situées en dehors de la diagonale de la matrice. Nous pouvons voir dans la matrice que la covariance entre \\(X\\) et \\(Y\\) est égale à 9602.306. Notez que ces nombres sont les mêmes dans la matrice, car il n’y a qu’une seule covariance entre \\(X\\) et \\(Y\\). Autrement dit, le nombre en bas à gauche de la matrice est le même que le nombre en haut à droite. La matrice de covariance est un exemple de matrice symétrique, ce qui signifie que la partie triangulaire supérieure de celle-ci est la même que la partie triangulaire inférieure. La raison pour laquelle nous avons construit une matrice de covariance de \\(X\\) et \\(Y\\) est que dans un instant nous demanderons à R d’effectuer une analyse en composantes directement sur cette matrice.\nPour la démonstration, et pour confirmer que nous avons créé notre matrice de covariance correctement (ainsi que R l’a calculée correctement), nous calculons les variances et la covariance de \\(X\\) et \\(Y\\) manuellement dans R. Tout d’abord, nous confirmons que les variances ont été calculées correctement en utilisant la fonction var()de R :\n\nvar(X)\n\n[1] 4541.111\n\nvar(Y)\n\n[1] 26455.78\n\n\nOn voit que les variances calculées correspondent à celles de la matrice de covariance. Nous aurions également pu utiliser la fonction diag() sur la matrice \\(A\\) pour obtenir les valeurs le long de la diagonale principale, qui correspondent bien sûr aux variances ci-dessus :\n\ndiag(A)\n\n        X         Y \n 4541.111 26455.778 \n\n\nNous pouvons enfin confirmer que les valeurs situées hors de la diagonale correspondent bien à la covariance de X et de Y :\n\ncov(X,Y)\n\n[1] 9602.306\n\n\n\n\nRéalisation de l’ACP\nAprès avoir produit notre matrice de covariance, nous sommes maintenant prêts à exécuter l’ACP dans R. Nous allons d’abord utiliser la fonction princomp() de R pour obtenir les résultats de l’ACP, puis nous montrerons plus tard une autre fonction dans R pour obtenir l’ACP directement à partir du tableau de données\n\nacp<-princomp(covmat=A)\nsummary(acp)\n\nImportance of components:\n                            Comp.1      Comp.2\nStandard deviation     173.4008211 30.48022510\nProportion of Variance   0.9700278  0.02997217\nCumulative Proportion    0.9700278  1.00000000\n\n\nQue nous apprend ce tableau d’un point de vue statistique ?\n\nl’écart-type de la composante 1 est de 173.4 ce qui signifie que sa variance (le carré de l’écart-type) est égale à 30067. Quand à la composante 2 son écart-type est égal à 30.48 ce qui signifie que sa variance est égale à 929. Si on somme ces deux variances on trouve une variance totale de 30996 qui est égale la somme des variances de X et de Y. La transformation opérée par l’ACP a donc conservée la variance totale (on dit aussi l’inertie) du tableau de départ.\nMais la variance a été redistribuée de façon à être désormais concentrée au maximum sur la première composante. Celle-ci représente en effet 30067/30996 = 97% de l’inertie totale, tandis que la second composante ne représente que 3% de l’inertie totale. Dans le tableau initial la variable X représentait 85.3% de l’inertie et la variable Y 14.7% de l’inertie. L’ACP a donc permis de mettre à jour une dimension fondamentale (composante 1) et une dimension résiduelle (composante 2)\n\n\n\nCoefficients de l’ACP\nPour bien comprendre la nature des deux nouvelles variables, il faut analyser la façon dont elles ont recomposé les variances initiales en opérant une transformation. Pour cela, nous allons demander à R d’afficher les coefficients de transformation des variables appelés en anglais loadings :\n\n\n\nLoadings:\n  Comp.1 Comp.2\nX  0.352  0.936\nY  0.936 -0.352\n\n               Comp.1 Comp.2\nSS loadings       1.0    1.0\nProportion Var    0.5    0.5\nCumulative Var    0.5    1.0\n\n\nQue signifient ces résultats ?\n\nla Composante 1 affiche un coefficient de 0.936 pour X et de 0.352 pour Y. Elle opère donc une transformation linéaire de la forme\n\n\\(F_1 = 0.936(X) + 0.352(Y)\\)\n\nla Composante 2 affiche un coefficient de 0.352 pour X et de -0.936 pour Y. Elle opère donc une transformation linéaire de la forme\n\n\\(F_2 = 0.352(X) - 0.936(Y)\\)\n\nLes valeurs SSloadings pour chaque composante font référence aux sommes des poids au carré des coefficients pour chaque colonne de chargements. Une des contraintes de l’ACP est que la somme des carrés des coefficients de chaque composante soit égale à 1.0. Il s’agit d’une contrainte mathématique permettant d’assurer la conservation des variances des composantes par rapport à la variance totale du tableau initial. On peut vérifier que c’est bien le cas en faisant la somme des carrés des coefficients de chacune des colonnes.\n\n\n(0.936)**2 + (0.352)**2\n\n[1] 1\n\n(0.352)**2 + (-0.936)**2\n\n[1] 1\n\n\n\n\nDétails mathématiques sur le calcul des coefficients\nVous vous demandez peut-être à ce stade comment sont obtenus les coefficients précédents. Nous savons qu’ils constituent des éléments de chaque composante, mais nous n’avons pas encore discuté de la manière dont ils sont réellement dérivées. Pour comprendre comment ils sont dérivés, nous devons introduire les concepts mathématiques de valeurs propres et de vecteurs propres.\nIl faut tout d’abord rappeler que que pour toute matrice carrée \\(\\boldsymbol{A}\\), il est mathématiquement admis qu’un scalaire \\(\\lambda\\) et un vecteur \\(X\\) peuvent être obtenus de sorte que l’égalité suivante soit vraie :\n\\(\\boldsymbol{A} X = \\lambda X\\)\nCela signifie que lorsque nous effectuons une transformation sur le vecteur \\(X\\) via la matrice \\(\\boldsymbol{A}\\), cela équivaut à transformer le vecteur \\(X\\) en le multipliant par un “scalaire spécial” \\(\\lambda\\). Ce scalaire est appelé valeur propre et \\(X\\) est appelé vecteur propre.\nEn utilisant la décomposition en vecteur propre et valeur propre, l’ACP opère une transformation de la matrice de covariance contenant les variables que nous avons soumises à l’ACP. Il y a encore beaucoup à apprendre sur l’analyse propre, et le lecteur intéressé est encouragé à consulter n’importe quel livre d’algèbre linéaire pour plus de détails, ou un livre complet qui discute de la théorie de l’analyse multivariée de manière plus approfondie, comme Johnson et Wichern (2007) ou Rencher et Christensen (2012). P\nSur le plan mathématique, la plupart des méthodes statistiques multivariées se réduisent, au niveau structurel, à l’analyse des valeurs propres. En R, nous pouvons démontrer que le calcul des valeurs propres et des vecteurs propres que nous avons obtenus dans l’ACP ci-dessus aurait pu l’être par une procédure purement mathématique, la fonction eigen(), applicable à n’importe quelle matrice :\n\neigen(A)\n\neigen() decomposition\n$values\n[1] 30067.8448   929.0441\n\n$vectors\n          [,1]       [,2]\n[1,] 0.3520806 -0.9359697\n[2,] 0.9359697  0.3520806\n\n\nNous pouvons vérifier que les valeurs propres générées de 30067.8 et 929.04 correspondent exactement à la variance des dimensions obtenues à partir de notre ACP. Nous pouvons également constater que les coefficients de transformation sont les mêmes à un changement de signe prêt (on verra par la suite que la valeur positive ou négative d’un axe est arbitraire).\n\n\nPropriétés des composantes principales\nDans notre exemple ci-dessus, nous avons calcule les composantes principales, mais nous n’avons abordé que quelques-unes de leurs propriétés. Nous résumons et développons ici cette discussion. Les composantes obtenues dans une ACP obéissent aux propriétés suivantes :\n\n1. La somme des valeurs propres des composantes dérivées de la matrice de covariance correspond à la somme des variances originales des variables brutes. Pour nos données, rappelons que la somme des variances des valeurs propres est égale à 30996. Ce nombre est le même que celui que nous obtenons en additionnant les variances originales, celles de de X (26455) et de Y (4541) = 30996. Pourquoi cette propriété est-elle importante ? Elle est essentielle pour comprendre ce que fait l’ACP, car elle révèle que l’ACP ne modifie pas la quantité d’“information” des variables d’origine en termes de variance qu’elles représentent, mais qu’elle transfère simplement cette information (variance) sur de nouvelles dimensions.\n2. Les composantes successives (qui, rappelons-le, sont des combinaisons linéaires des variables d’origine) sont orthogonales. Lorsque l’on obtient des composantes principales, la première composante obtenue est celle qui explique le plus possible la variance des variables originales. Il s’agit de la première composante principale. La seconde composante obtenue explique le maximum de variance des variables d’origine, mais avec la contrainte qu’elle soit orthogonale à la première composante. De cette façon, les composantes extraites ne se chevauchent pas.\n3. La somme des coefficients au carré pour chaque composante est égale à 1.0. C’est-à-dire que lavariance de chaque composante est maximisée sous réserve de la contrainte que la longueur de chaque composante soit égale à 1.0. Pourquoi cette contrainte est-elle pertinente ? Elle est importante parce que si nous ne soumettons pas les composantes à une telle contrainte, alors en théorie, la variance de la composante donnée pourrait croître sans limite. Autrement dit, la variance de la composante pourrait devenir de plus en plus grande si nous n’avions pas un moyen de la réguler. Le fait de contraindre la somme des coefficients au carré d’être égale à 1.0 est une façon de s’assurer que la variance de chaque composante est “maîtrisée” dans un certain sens.\n4. La transformation opérée par l’ACP correspond à un centrage (sur la moyenne des variables) et une rotation des coordonnées . La position relative des points les uns par rapport aux autres n’est donc pas modifié, ce qui explique que la variance totale soit préservée.\n\n\n\n\n\n\n\n\nCoordonnées des individus sur les composantes\nUne fois définies les composantes par rapport aux variables, on peut s’intéresser aux individus qui composent le tableau en calculant leurs coordonnées (en anglais scores) dans le nouveau repère. Ces coordonnées sont obtenues en procédant aux opérations de centrage et de réduction en se servant des coefficients des variables obtenus précédemment. La coordonnées \\(F_i^1\\) de l’individu \\(i\\) sur la composante 1 ou la coordonnée \\(F_i^2\\) de l’individu \\(i\\) sur la composante 2 seront obtenus à l’aide des calculs suivants :\n\\(\\begin{cases}F^1_i = a_1(X_i - \\bar{X}) + b_1(Y_i - \\bar{Y})\\\\F^2_i = a_2(X_i - \\bar{X}) + b_2(Y_i - \\bar{Y}) \\end{cases}\\)\nOn en déduit le tableau ci-dessous qui fournit pour chaque individu (ici chaque pays) ses coordonnées sur chacune des deux composantes :\n\n\n\n\nCoordonnées des individus\n \n  \n      \n    code \n    F1 \n    F2 \n  \n \n\n  \n    1 \n    AFR_Sud \n    -28.6 \n    101.9 \n  \n  \n    2 \n    AFR_Centre \n    -114.1 \n    153.1 \n  \n  \n    3 \n    AFR_Ouest \n    -126.0 \n    133.6 \n  \n  \n    4 \n    AFR_Est \n    -97.1 \n    96.4 \n  \n  \n    5 \n    AFR_Nord \n    -103.9 \n    26.6 \n  \n  \n    6 \n    EUR_Sud \n    90.0 \n    -88.5 \n  \n  \n    7 \n    EUR_Ouest \n    166.9 \n    -204.9 \n  \n  \n    8 \n    EUR_Est \n    97.0 \n    -64.5 \n  \n  \n    9 \n    EUR_Nord \n    115.6 \n    -153.7 \n  \n\n\n\n\n\nOn peut également visualiser graphiquement ces nouvelles coordonnées issues du centrage et de la rotation effectuée par l’ACP :\n\n\n\n\n\n\n\nInterprétation des composantes\nUne fois calculés les coefficients des variables et les coordonnées des individus, il reste à donner une signification aux composantes. Nous avons en effet transformer les variables initiales en des composantes qui concentrent davantage l’information. Mais cette transformation n’est intéressante que si l’on est capable d’interpréter les résultats. Or, toutes les composantes ne sont pas forcément interprétables et on se limitera le plus souvent à l’interprétation des deux ou trois premières.\nDans notre premier exemple, on devine de façon intuitive qu’il est assez simple d’interpréter les résultats :\n\nla composante 1 exprime le niveau global de consommation de lait ET d’alccol puisque les variables lait et d’alcool sont positivement corrélées entre elles et avec cette composante. Elle oppose donc les pays à forte consommation de lait ET d’alcool et les pays à faible consommation. Elle recoupe visiblement une opposition entre des populations plus riches qui peuvent s’offrir les deux produits (Europe) et des populations plus pauvres (Afrique) qui consomment moins ces produits.\nla composante 2 exprime une préférence relative pour le lait OU l’alcool. Comme elle est orthogonale à la première composante, elle va mettre en évidence des différences résiduelles non prises en compte par la composante 1. Elle exprime donc un choix toutes choses égales quant au niveau global de consommation de ces deux boissons. La mention “toutes choses égales” est essentielle pour souligner que ces excédents ou déficits sont relatifs au niveau global de consommation des deux boissons.\n\nLa position d’un pays sur le graphique (ses coordonnées sur les axes F1 et F2) va donc nous permettre de le caractériser par rapport à nos deux nouveaux indicateurs. Par exemple :\n\nl’Europe de l’Ouest a une coordonnée fortement positive de +264 sur la composante 1 qui indique une très forte consommation des deux boissons. Sa coordonnée sur la composante 2 est très faible (+9) ce qui signifie qu’il n’y a pas de préférence particulière pour l’une ou l’autre des deux boissons.\nl’Afrique de l’Ouest présente une situation opposée avec une coordonnée de -184 sur la composante 1 qui signale une très faible consommation des deux boissons. Sa coordonnée sur la composante 2 est très faible (+7) ce qui indique, comme en Europe, une absence de préférence pour l’une ou l’autre boisson.\nL’Afrique du Nord affiche une consommation faible des deux boissons (-88) mais relativementplus forte que celle de l’Afrique de l’Ouest. Elle se caractérise par une coordonnée fortement positive sur l’axe 2 (+60) qui indique une préférence pour le lait par rapport à l’alcool, toutes choses égales quant au niveau de consommation. Le facteur religieux explique naturellement dans une large mesure ce résultat.\nl’Afrique australe présente une consommation globale assez voisine de celle de l’Afrique du Nord (-95) au vu de la composante 1. Mais elle montre un comportement opposé sur l’axe 2 (-46) qui signifie une préférence pour l’alcool par rapport au lait, toutes choses égales par ailleurs. Il n’y a pas dans cette région d’interdit religieux de l’alcool et le climat favroise la culture de la vigne et donc la consommation de vin…\n\n\n\nAides à l’interprétation\nNous avons procédé dans le paragraphe précédent à une interprétation rapide des résultats car les explications étaient relativement simples et évidentes. Mais dans le cas de tableau de données plus important, il est souvent plus délicat de donner un sens aux composantes. Il est alors utile de mobliser des aides à l’interprétation, notamment en examinant les contributions des variables et des individus à la constitution des composantes.\nLes aides à l’interprétation sont faciles à obtenir en utilisant le package FactoMineR.\n\n\n\n\nContribution des variables aux composantes\n\n\n\n\nContribution des variables aux composantes\n \n  \n      \n    Dim.1 \n    Dim.2 \n  \n \n\n  \n    X \n    12.4 \n    87.6 \n  \n  \n    Y \n    87.6 \n    12.4 \n  \n  \n    Sum \n    100.0 \n    100.0 \n  \n\n\n\n\n\n\nCommentaire : la variable qui contribue le plus à la constitution de la composante 1 est la variable X (87.6%) ce qui est logique puisque c’est elle qui possédait la variance la plus importante. La variable Y contribue inversement pour l’essentiel à la constitution de la composante 2.\n\n\n\nContribution des individus aux composantes\nOn peut proposer une seconde lecture en repérant les individus qui contribuent le plus à la constitution des axes en raison de leurs positions extrêmes par rapport aux variables.\n\n\n\n\nContribution des individus aux composantes\n \n  \n      \n    Dim.1 \n    Dim.2 \n  \n \n\n  \n    Afrique australe \n    3.8 \n    28.0 \n  \n  \n    Afrique centrale \n    15.1 \n    3.1 \n  \n  \n    Afrique occidentale \n    14.0 \n    0.6 \n  \n  \n    Afrique orientale \n    7.7 \n    1.2 \n  \n  \n    Afrique septentrionale \n    3.3 \n    49.5 \n  \n  \n    Europe méridionale \n    6.6 \n    1.2 \n  \n  \n    Europe occidentale \n    29.0 \n    1.2 \n  \n  \n    Europe orientale \n    5.3 \n    12.5 \n  \n  \n    Europe septentrionale \n    15.3 \n    2.8 \n  \n  \n    Sum \n    100.0 \n    100.0 \n  \n\n\n\n\n\n\nCommentaire : les individus qui contribuent le plus à la constitution de la composante 1 sont les pays à très forte consommation comme l’Europe occidentale (29.0%) et l’Europe septentrionale (15.3%) ou les pays à très faible consommation comme l’Afrique centrale (15.1%) et l’Afrique occidentale (14%). Ce sont les pays situés aux extrémités opposés de la composante 1. En ce qui concerne la composante 2, elle est clairement déterminée par l’opposition entre l’Afrique septentrionale (49.5%), d’une part, et l’Afrique australe (28.0%) ou l’Europe orientale (12.5%), d’autre part. Comme nous l’avons vu, cela est lié au fait que, toutes choses égales quant à la consommation globale, l’Afrique septentrionale consomme moins d’alcool et plus de lait, tandis que les deux autres régions consomment plus d’alcool et moins de lait.\n\nIl existe d’autres aides à l’interprétation que nous ne détaillerons pas pour l’instant et qui seront vus ultérieurement en travaux dirigés.\n\n\n\nACP normé ou non normé ?\nTout au long de ce cours nous avons appliqué la méthode d’ACP non normée fondée sur la recherche de valeurs propres et vecteurs propres à partir de la matrice de covariance. La particularité de cette méthode est de laisser chaque variable du tableau initial contribuer à proportion de sa variance. Dans notre exemple, la variance de la variable X (consommation d’alcool) était beaucoup plus forte que celle de la variable Y (consommation de lait) de sorte que la constitution des composantes principale a été déterminée en premier lieu par X.\nMais on aurait pu utiliser la méthode plus fréquente de l’ACP normée qui se fonde sur la recherche des valeurs propres et des vecteurs propres de la matrice de corrélation. Dans ce cas, la variance de chacune des variables du tableau initial est ramenée à 1 et leur moyenne à 0 (variables centrées-réduites), ce qui signifie que chacune d’entre elles contribuera de façon identique à la constitution des composantes. Le résultat sera lors différent comme on peut le voir sur la figure présentant les coefficients et les coordonnées des deux analyses.\n\n\n\n\n\nComparaison d’ACP normées et non normées\n\n\n\n\n\nCommentaire : Les résultats des deux analyses sont ici très proches mais on peut noter que la part de variance expliquée par la composante 1 est plus faible dans le cas de l’ACP normée (93.8%) que dans celui de l’ACP non normée (97.0%). On note également que cans le cas de l’ACP normée, les coefficients des variables ont une somme de carré égale à 1, ce qui permet de les représenter à l’intérieur d’un cercle des corrélations ou l’angle que fait une variable avec un facteur est d’autant plus faible que la corrélation est forte. On voit donc tout de suite que l’axe 1 est fortement corrélé positivement avec les variables X et Y tandis que l’axe 2 oppose ces deux variables.\n\n\n\nQuelle méthode choisir ?\nD’un point de vue théorique, les deux méthodes peuvent apporter des résultats intéressants et on peut être amené à choisir l’une ou l’autre. Néanmoins nous conseillons au débutant de\n\nToujours choisir l’ACP normée lorsque les unités de mesure des variables sont différentes. Car il y a de fortes chances que les variance ne soient pas de nature et d’ordre de grandeur comparable si on mélange des variables telles que la densité de population, le taux de mortalité infantile ou le nombre d’enfants par femme.\nCommencer par une ACP normée lorsque les unités de mesure sont comparables puis confronter dans un deuxième temps les résultats à ceux d’une ACP non normée et examiner les différences."
  },
  {
    "objectID": "ACP-Cours.html#exemple-dapplication",
    "href": "ACP-Cours.html#exemple-dapplication",
    "title": "Introduction à l’ACP",
    "section": "EXEMPLE D’APPLICATION",
    "text": "EXEMPLE D’APPLICATION\n\nDonnées\nOn reprend les données FAOSTAT utilisées dans l’exemple pédagogique de cours, mais en conservant l’ensemble des variables relatives à la consommation calorique des habitants des régions d’Europe et d’Afrique. Nous procédons toutefois à des regroupements en cinq types principaux d’apports caloriques :\n\nViandes : abats, viandes, poissons, lait, graisses animales, …\nCéréales : blé, maïs, riz, sorgho…\nHuiles : cultures oléagineuses, huiles végétales\nSucres : cultures sucrières, sucres et édulcorants\nLégumes: légumes, fruits, ignames, pommes de terres, …\nDivers : épices, stimulants, boissons alcooliques\n\n\n\n\n\n\n\n\nConsommation alimentaire en kCal/pers/jou (tableau brut)\n \n  \n      \n    Animaux \n    Céréales \n    Légumes \n    Huiles \n    Sucres \n    Divers \n  \n \n\n  \n    AFR_Sud \n    448 \n    1358 \n    114 \n    421 \n    300 \n    161 \n  \n  \n    AFR_Centre \n    113 \n    633 \n    1048 \n    249 \n    76 \n    138 \n  \n  \n    AFR_Ouest \n    120 \n    1209 \n    692 \n    359 \n    108 \n    214 \n  \n  \n    AFR_Est \n    165 \n    1178 \n    380 \n    197 \n    107 \n    229 \n  \n  \n    AFR_Nord \n    326 \n    1819 \n    243 \n    363 \n    304 \n    183 \n  \n  \n    EUR_Sud \n    876 \n    970 \n    297 \n    650 \n    305 \n    311 \n  \n  \n    EUR_Ouest \n    1202 \n    882 \n    294 \n    506 \n    408 \n    300 \n  \n  \n    EUR_Est \n    897 \n    1138 \n    272 \n    385 \n    370 \n    281 \n  \n  \n    EUR_Nord \n    1051 \n    971 \n    271 \n    463 \n    298 \n    341 \n  \n\n\n\n\n\nOn examine pour chaque variable quelques paramètres principaux afin d’évaluer le rôle potentiel qu’elles vont jouer dans une ACP selon que celle-ci sera normée ou non.\n\n\n\n\nParamètres principaux des variables brutes\n \n  \n      \n    Animaux \n    Céréales \n    Légumes \n    Huiles \n    Sucres \n    Divers \n  \n \n\n  \n    Moyenne \n    577.6 \n    1128.7 \n    401.22 \n    399 \n    252.9 \n    239.8 \n  \n  \n    écart-type \n    430.2 \n    334.4 \n    288.72 \n    135 \n    122.9 \n    71.8 \n  \n  \n    coeff. de variation \n    0.7 \n    0.3 \n    0.72 \n    0 \n    0.5 \n    0.3 \n  \n  \n    variance \n    185078.8 \n    111836.5 \n    83358.69 \n    18178 \n    15115.4 \n    5151.7 \n  \n  \n    variance (%) \n    44.2 \n    26.7 \n    19.91 \n    4 \n    3.6 \n    1.2 \n  \n\n\n\n\n\nCe tableau montre que certaines variables créent beaucoup plus de différences que d’autres entre les pays, en particulier la consommation de produits animaux qui représenterait 44% de la variance totale si on effectuait une ACP non normée. Les céréales, qui sont pourtant davantage consommée génèrent une variance plus faible (26.7%). Les légumes enfin présentent comme la viande une très forte variabilité (c.v. = 0.7) alors même que leur poids dans le régime alimentaire est plus limitéque celui des céréales.\nOn décide dans le cas présent d’effectuer une ACP normée, ce qui revient à modifier le tableau initial et à le remplacer par des variables centrées et réduites :\n\n\n\n\nConsommation alimentaire en kCal/pers/jou (tableau standardisé)\n \n  \n      \n    Animaux \n    Céréales \n    Légumes \n    Huiles \n    Sucres \n    Divers \n  \n \n\n  \n    AFR_Sud \n    -0.30 \n    0.69 \n    -0.99 \n    0.16 \n    0.38 \n    -1.10 \n  \n  \n    AFR_Centre \n    -1.08 \n    -1.48 \n    2.24 \n    -1.11 \n    -1.44 \n    -1.42 \n  \n  \n    AFR_Ouest \n    -1.06 \n    0.24 \n    1.01 \n    -0.30 \n    -1.18 \n    -0.36 \n  \n  \n    AFR_Est \n    -0.96 \n    0.15 \n    -0.07 \n    -1.50 \n    -1.19 \n    -0.15 \n  \n  \n    AFR_Nord \n    -0.58 \n    2.06 \n    -0.55 \n    -0.27 \n    0.42 \n    -0.79 \n  \n  \n    EUR_Sud \n    0.69 \n    -0.47 \n    -0.36 \n    1.86 \n    0.42 \n    0.99 \n  \n  \n    EUR_Ouest \n    1.45 \n    -0.74 \n    -0.37 \n    0.79 \n    1.26 \n    0.84 \n  \n  \n    EUR_Est \n    0.74 \n    0.03 \n    -0.45 \n    -0.11 \n    0.95 \n    0.57 \n  \n  \n    EUR_Nord \n    1.10 \n    -0.47 \n    -0.45 \n    0.47 \n    0.37 \n    1.41 \n  \n\n\n\n\n\nCe nouveau tableau est désormais exprimé en distance à la moyenne mesurée en écart-type. Il permet de repérer facilement les consommations exceptionelles fortes de certains produits dans certaines régions , notamment les céréales en Afrique du Nord (+2.06) ou les légumes en Afrique Centrale (+2.24). En sens inverse on repère des consommations inéférieures à la moyenne telles que les produis animaux dans l’ensemble de l’Afrique, les céréales en Afrique centrale (-1.48), les huiles en Afrique de l’Est (-1.50), etc.\nDu fait de sa transformation, le tableau standardisé offre désormais une contribution égale à chacune des variables puisqu’elles ont toutes une moyenne égale à 0 et un écart-type égal à 1. La part de variance apportée par chacune des six variables sera donc de 1/6 = 16.7%\n\n\n\n\nParamètres principaux des variables standardisées\n \n  \n      \n    Animaux \n    Céréales \n    Légumes \n    Huiles \n    Sucres \n    Divers \n  \n \n\n  \n    moyenne \n    0.0 \n    0.0 \n    0.0 \n    0.0 \n    0.0 \n    0.0 \n  \n  \n    écart-type \n    1.0 \n    1.0 \n    1.0 \n    1.0 \n    1.0 \n    1.0 \n  \n  \n    variance \n    1.0 \n    1.0 \n    1.0 \n    1.0 \n    1.0 \n    1.0 \n  \n  \n    variance (%) \n    16.7 \n    16.7 \n    16.7 \n    16.7 \n    16.7 \n    16.7 \n  \n\n\n\n\n\n\n\nExamen de la matrice des corrélations\nAvant de procéder à l’ACP, on examine les corrélations entre les variables à l’aide de la fonction cor()\n\n\n\n\nCoefficient de corrélation de Pearson\n \n  \n      \n    Animaux \n    Céréales \n    Légumes \n    Huiles \n    Sucres \n    Divers \n  \n \n\n  \n    Animaux \n    1.00 \n    -0.26 \n    -0.55 \n    0.74 \n    0.85 \n    0.84 \n  \n  \n    Céréales \n    -0.26 \n    1.00 \n    -0.53 \n    -0.10 \n    0.19 \n    -0.27 \n  \n  \n    Légumes \n    -0.55 \n    -0.53 \n    1.00 \n    -0.48 \n    -0.77 \n    -0.45 \n  \n  \n    Huiles \n    0.74 \n    -0.10 \n    -0.48 \n    1.00 \n    0.69 \n    0.63 \n  \n  \n    Sucres \n    0.85 \n    0.19 \n    -0.77 \n    0.69 \n    1.00 \n    0.55 \n  \n  \n    Divers \n    0.84 \n    -0.27 \n    -0.45 \n    0.63 \n    0.55 \n    1.00 \n  \n\n\n\n\n\nOn peut compléter cette matrice par une visualisation de la forme des relations entre l’ensemble des paires de variables à l’aide de la fonction pairs() de R-base ou, mieux encore, de la fonction ggpairs() du packageGGally. Cette dernière ajoute un test de significativité pour chaque corrélation.\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\n\n\n\n\n\n\n\nCaclul de l’ACP\nOn va utiliser le package FactomineR pour réaliser l’analyse en composante principales à l’aide de la fonction PCA(). Le programme-type ci-dessous permet d’obtenir rapidement l’essentiel des résultats :\n.\n\nlibrary(FactoMineR)\nmonACP <- PCA(don2s)\n\n\n\n\n\n\nsummary(monACP)\n\n\nCall:\nPCA(X = don2s) \n\n\nEigenvalues\n                       Dim.1   Dim.2   Dim.3   Dim.4   Dim.5   Dim.6\nVariance               3.648   1.544   0.385   0.298   0.121   0.005\n% of var.             60.794  25.725   6.422   4.963   2.017   0.079\nCumulative % of var.  60.794  86.519  92.941  97.904  99.921 100.000\n\nIndividuals\n               Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3\nAFR_Sud    |  1.815 |  0.033  0.003  0.000 | -1.510 16.406  0.692 |  0.627\nAFR_Centre |  3.926 | -3.396 35.128  0.748 |  1.821 23.873  0.215 |  0.497\nAFR_Ouest  |  2.070 | -1.874 10.696  0.819 |  0.143  0.147  0.005 |  0.176\nAFR_Est    |  2.282 | -1.835 10.254  0.647 | -0.379  1.032  0.028 | -1.211\nAFR_Nord   |  2.549 | -0.339  0.350  0.018 | -2.461 43.616  0.933 |  0.245\nEUR_Sud    |  2.479 |  2.038 12.646  0.676 |  0.808  4.704  0.106 |  0.757\nEUR_Ouest  |  2.535 |  2.297 16.076  0.821 |  0.860  5.328  0.115 |  0.066\nEUR_Est    |  1.500 |  1.270  4.910  0.716 | -0.101  0.074  0.005 | -0.479\nEUR_Nord   |  2.117 |  1.806  9.937  0.728 |  0.818  4.820  0.149 | -0.680\n              ctr   cos2  \nAFR_Sud    11.351  0.119 |\nAFR_Centre  7.126  0.016 |\nAFR_Ouest   0.896  0.007 |\nAFR_Est    42.271  0.282 |\nAFR_Nord    1.732  0.009 |\nEUR_Sud    16.546  0.093 |\nEUR_Ouest   0.127  0.001 |\nEUR_Est     6.615  0.102 |\nEUR_Nord   13.337  0.103 |\n\nVariables\n              Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2\nAnimaux    |  0.943 24.391  0.890 |  0.263  4.484  0.069 | -0.072  1.334  0.005\nCéréales   |  0.010  0.003  0.000 | -0.972 61.175  0.944 | -0.007  0.014  0.000\nLégumes    | -0.751 15.481  0.565 |  0.585 22.172  0.342 |  0.160  6.674  0.026\nHuiles     |  0.834 19.082  0.696 |  0.142  1.305  0.020 |  0.462 55.479  0.214\nSucres     |  0.912 22.794  0.831 | -0.219  3.109  0.048 |  0.105  2.883  0.011\nDivers     |  0.816 18.248  0.666 |  0.346  7.755  0.120 | -0.360 33.616  0.130\n            \nAnimaux    |\nCéréales   |\nLégumes    |\nHuiles     |\nSucres     |\nDivers     |\n\n\nComme on peut le voir, l’application de la fonction PCA provoque l’apparition de deux graphiques, l’un relatif aux variables et l’autre aux individus. Quant à la fonction summary, elle génère des tableaux relatifs soit aux variables, soit aux individus. `\n\n\nAnalyse des valeurs propres\nL’analyse des valeurs propres permet de savoir quelle est la part de variance prise en compte par chacun des facteurs (on dit aussi composantes) de l’analyse. Les facteurs sont orthogonaux c’est-à-dire statistiquement indépendants (corrélation = 0). Le premier facteur est celui qui résume le mieux le nuage de point. Puis le second facteur est celui qui résume le maximum de variance résiduelle, etc. Il y a autant de facteurs que de variables de sorte que les facteurs sont d’autant plus pertinents qu’ils résument une part de la variance supérieure à 1/k ou k est le nombre de variables. Les facteurs qui résument plus qu’une variable ont une valeur propre supérieure à 1 et doivent être interprétés en priorité.\n\n\n\n\nTableau des valeurs propres\n \n  \n      \n    Valeurs propres \n    Variance (%) \n    Variance cumulée (%) \n  \n \n\n  \n    comp 1 \n    3.65 \n    60.79 \n    60.79 \n  \n  \n    comp 2 \n    1.54 \n    25.73 \n    86.52 \n  \n  \n    comp 3 \n    0.39 \n    6.42 \n    92.94 \n  \n  \n    comp 4 \n    0.30 \n    4.96 \n    97.90 \n  \n  \n    comp 5 \n    0.12 \n    2.02 \n    99.92 \n  \n  \n    comp 6 \n    0.00 \n    0.08 \n    100.00 \n  \n\n\n\n\n\n\nLe premier facteur résumé 60.8% de la variance totale des six variables. Chaque variable comptant pour 1/6e = 16.7%, sa valeur propre est égale à 60.8 / 16.7 = 3.65. Il est donc très significatif et résume à lui seul l’effet de presque quatre variables initiales.\nLe second facteur résume quant à lui 25.7% de la variance totale, ce qui plus qu’une variable isolée et lui donne donc une valeur propre de 25.7/16.7 = 1.54. Il demeure de ce fait interprétable et, combiné avec le premier facteur il permet de rendre compte de 86.5% de la variance totale c’est-à-dire de l’information\n\nLes facteurs suivants ont des valeurs propres très faibles (<1) et ne seront donc pas analysés dans la suite puisque notre objectif est de résumer l’information à l’aide d’un nombre d’indicateurs plus faible que le nombre initial de variables.\n\n\nAnalyse des corrélations des variables avec les facteurs\nNous avons donc retenu deux facteurs mais il faut maintenant les interpréter en examinant les variables qui en sont responsables. Nous allons pour cela extraire trois autres tableaux mesurant les corrélations des variables avec les facteurs ainsi que leurs contributions à la constitution de ceux-ci.\n\n\n\n\n Corrélation des variables avec les facteurs\n \n  \n      \n    Dim.1 \n    Dim.2 \n    Dim.3 \n    Dim.4 \n    Dim.5 \n  \n \n\n  \n    Animaux \n    0.94 \n    0.26 \n    -0.07 \n    -0.17 \n    0.05 \n  \n  \n    Céréales \n    0.01 \n    -0.97 \n    -0.01 \n    0.16 \n    0.17 \n  \n  \n    Légumes \n    -0.75 \n    0.58 \n    0.16 \n    0.00 \n    0.26 \n  \n  \n    Huiles \n    0.83 \n    0.14 \n    0.46 \n    0.26 \n    -0.03 \n  \n  \n    Sucres \n    0.91 \n    -0.22 \n    0.11 \n    -0.31 \n    0.11 \n  \n  \n    Divers \n    0.82 \n    0.35 \n    -0.36 \n    0.28 \n    0.09 \n  \n\n\n\n\n\n\n\n Contribution des variables aux facteurs\n \n  \n      \n    Dim.1 \n    Dim.2 \n    Dim.3 \n    Dim.4 \n    Dim.5 \n  \n \n\n  \n    Animaux \n    24.39 \n    4.48 \n    1.33 \n    10.18 \n    2.40 \n  \n  \n    Céréales \n    0.00 \n    61.18 \n    0.01 \n    8.53 \n    24.75 \n  \n  \n    Légumes \n    15.48 \n    22.17 \n    6.67 \n    0.00 \n    55.66 \n  \n  \n    Huiles \n    19.08 \n    1.31 \n    55.48 \n    23.12 \n    0.98 \n  \n  \n    Sucres \n    22.79 \n    3.11 \n    2.88 \n    32.36 \n    9.67 \n  \n  \n    Divers \n    18.25 \n    7.75 \n    33.62 \n    25.81 \n    6.53 \n  \n\n\n\n\n\n\nle premier facteur est très fortement corrélé positivement avec la consommation de produits animaux (+0.94), de sucres (+0.91), d’huiles (+0.83) et de produits divers (+0.82). Il est corrélé négativement avec la consommation de légumes (-0.75) . Il n’est pas corrélé du tout avec la consommation de céréales (+0.01). L’analyse des contribution confirme que ce facteur est déterminé de façon approximativement équivalente par 5 des 6 variables mais pas du tout par la consommation de céréales. Au total, ce premier facteur oppose donc des régions à forte consommation de viandes, huiles ou sucre à des régions consommant prioritairement des légumes. La consommation de céréales n’intervient pas dans cette dimension.\nle second facteur est quant à lui précisément par la consommation de céréales qui est très fortement corrélée négativement (-0.97) et s’oppose à la consommaion de dont la contribution est de 61%. La consommation de légume se situe à l’opposé de cet axe avec une corrélation de +0.58 et une contribution de 22%. Ce deuxième facteur met donc en évidence une opposition entre les régions dont le régime alimentaire est plutôt tourné vers les légumes ou plutôt tourné vers les céréales, toutes choses égales quant à la consommation générale d’animaux, sucre ou huile qui a été prise en compte par le premier facteur.\n\nOn peut maintenant visualiser à nouveau la figure générée automatiquement par FactoMineR afin de comprendre sa signification.\n\n\n\n\n\n\nCommentaire : Pour chaque variable, l’angle qu’elle fait avec l’un ou l’autre des deux axes correspond à son niveau de corrélation. Quant à la longueur du vecteur, elle permet de savoir si la variable est convenablement représenté par l’un ou l’autres des deux axes. Ici toutes les variables sont bien représentées et on retrouve grahiquement les résultats obtenus par l’analyse détaillée des tableaux de corrélation et contribution.\n\n\n\nAnalyse des coordonnées des individus sur les facteurs\nNous allons maintenant examiner comment les individus se positionnent sur les facteurs. Comme dans le cas précédent, nous allons extraire deux tableaux, l’un correspondant aux coordonnées des individus sur les facteurs, l’autre à leur contribution à la constitution des facteurs.\n\n\n\n\n Coordonnées des individus sur les facteurs\n \n  \n      \n    Dim.1 \n    Dim.2 \n    Dim.3 \n    Dim.4 \n    Dim.5 \n  \n \n\n  \n    AFR_Sud \n    0.03 \n    -1.51 \n    0.63 \n    -0.42 \n    -0.66 \n  \n  \n    AFR_Centre \n    -3.40 \n    1.82 \n    0.50 \n    -0.56 \n    0.07 \n  \n  \n    AFR_Ouest \n    -1.87 \n    0.14 \n    0.18 \n    0.80 \n    0.29 \n  \n  \n    AFR_Est \n    -1.83 \n    -0.38 \n    -1.21 \n    0.24 \n    -0.41 \n  \n  \n    AFR_Nord \n    -0.34 \n    -2.46 \n    0.25 \n    0.02 \n    0.51 \n  \n  \n    EUR_Sud \n    2.04 \n    0.81 \n    0.76 \n    0.85 \n    -0.21 \n  \n  \n    EUR_Ouest \n    2.30 \n    0.86 \n    0.07 \n    -0.62 \n    0.12 \n  \n  \n    EUR_Est \n    1.27 \n    -0.10 \n    -0.48 \n    -0.56 \n    0.26 \n  \n  \n    EUR_Nord \n    1.81 \n    0.82 \n    -0.68 \n    0.26 \n    0.03 \n  \n\n\n\n\n\n\n\n Contribution des individus aux facteurs\n \n  \n      \n    Dim.1 \n    Dim.2 \n    Dim.3 \n    Dim.4 \n    Dim.5 \n  \n \n\n  \n    AFR_Sud \n    0.00 \n    16.41 \n    11.35 \n    6.72 \n    40.35 \n  \n  \n    AFR_Centre \n    35.13 \n    23.87 \n    7.13 \n    11.77 \n    0.46 \n  \n  \n    AFR_Ouest \n    10.70 \n    0.15 \n    0.90 \n    23.76 \n    7.94 \n  \n  \n    AFR_Est \n    10.25 \n    1.03 \n    42.27 \n    2.16 \n    15.64 \n  \n  \n    AFR_Nord \n    0.35 \n    43.62 \n    1.73 \n    0.02 \n    23.93 \n  \n  \n    EUR_Sud \n    12.65 \n    4.70 \n    16.55 \n    26.73 \n    3.99 \n  \n  \n    EUR_Ouest \n    16.08 \n    5.33 \n    0.13 \n    14.54 \n    1.24 \n  \n  \n    EUR_Est \n    4.91 \n    0.07 \n    6.61 \n    11.74 \n    6.38 \n  \n  \n    EUR_Nord \n    9.94 \n    4.82 \n    13.34 \n    2.56 \n    0.08 \n  \n\n\n\n\n\n\nle premier axe oppose très clairement les quatre régions d’Europe (coordonnées fortement positives) aux trois régions d’Afrique centrale, orientale et occidentale (coordonnées fortement négatives). L’Afrique septentrionale et l’Afrique australe ont des coordonnées plus proches de zéro et sont donc moins concernées par l’opposition. L’analyse des contributions confirme que l’opposition principale se fait entre l’Afrique centrale (35%), l’Afrique de l’ouest (11%) et l’Afrique de l’ouest (10%), d’une part, et l’Europe de l’ouest (16%), l’Europe du sud (13%) ou l’Europe du nord (10%) d’autre part. Alors que les pays africains se caractérisent par une plus forte consommation de légumes (ignames, manioc, etc.), les pays européens se caractérisent par une plus forte consommation de viandes, huiles, sucres et autres produits divers.\nle second axe met à jour une opposition secondaire, liée à la part des céréales dans le régime alimentaire. Elle oppose cette fois-ci nettement l’Afrique du Nord et l’Afrique du Sud à l’Afrique centrale, les deux premières ayant un régime à forte proportion de céréales tandis que les légumes prédominent dans la dernière. Les autres régions ont des contributions plus faibles\n\nOn peut maintenant visualiser à nouveau la figure générée automatiquement par FactoMineR\n\n\n\n\n\n\nCommentaire : A partir du moment où l’on a bien interprété la signification des axes, il devient plus facile de comprendre ce que signifie la position de chaque pays. Les proximités entre les points permettent par ailleurs de visualiser des proximités entre individus\n\n\n\nAjout de variables et d’individus supplémentaires\nIl est possible d’ajouter dans une ACP des variables supplémentaires et des individus supplémentaires qui correspondent respectivement à l’ajout de lignes et de colonnes au tableau initial. Ces variables et individus supplémentaires ne changent pas les composantes de l’ACP puisque leur contribution sera nulle. Mais on peut calculer les corrélations des variables supplémentaires avec les facteurs ainsi que les coordonnées des individus supplémentaires sur les axes.\n\n\n\n\nAjout d'un individu et d'une variable supplémentaires\n \n  \n      \n    Animaux \n    Céréales \n    Légumes \n    Huiles \n    Sucres \n    Divers \n    TOTAL \n  \n \n\n  \n    AFR_Sud \n    448 \n    1358 \n    114 \n    421 \n    300 \n    161 \n    2802 \n  \n  \n    AFR_Centre \n    113 \n    633 \n    1048 \n    249 \n    76 \n    138 \n    2257 \n  \n  \n    AFR_Ouest \n    120 \n    1209 \n    692 \n    359 \n    108 \n    214 \n    2702 \n  \n  \n    AFR_Est \n    165 \n    1178 \n    380 \n    197 \n    107 \n    229 \n    2256 \n  \n  \n    AFR_Nord \n    326 \n    1819 \n    243 \n    363 \n    304 \n    183 \n    3238 \n  \n  \n    EUR_Sud \n    876 \n    970 \n    297 \n    650 \n    305 \n    311 \n    3409 \n  \n  \n    EUR_Ouest \n    1202 \n    882 \n    294 \n    506 \n    408 \n    300 \n    3592 \n  \n  \n    EUR_Est \n    897 \n    1138 \n    272 \n    385 \n    370 \n    281 \n    3343 \n  \n  \n    EUR_Nord \n    1051 \n    971 \n    271 \n    463 \n    298 \n    341 \n    3395 \n  \n  \n    Bénin \n    113 \n    1092 \n    832 \n    402 \n    106 \n    304 \n    2849 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterprétaton de la variable supplémentaire TOTAL  : La variable supplémentaire TOTAL, qui représente la consommation totale en kCal/pers/jour est corrélées positivement de façon presque parfaite avec l’axe 1 (+0.93). Elle permet de montrer que l’axe 1 ne décrit pas simplement une différence qualitative de régime alimentaire (légumes / viandes, huiles ou sucre) mais plutôt une différence quantitative (faible / fort niveau de kCal).\nInterprétation de l’individu supplémentaire Bénin : l’ajout du Bénin au tableau ne modifie pas non plus les composantes factorielles mais il permet de situer sa position par rapport aux autres individus dans le plan factoriel des axes 1 et 2. On voit alors que sa position est très proche de celle de sa région d’appartenance (Afrique de l’Ouest) mais aussi de la région voisine d’Afrique Centrale. Son régime alimentaire est donc caractérisé par une ration alimentaire plutôt faible avec peu de viandes, huile ou sucre (coordonnées négatives sur l’axe 1) mais aussi une quantité relativement plus importante de légumes que de céréales (coordonnées positives sur l’axe 2).\n\n\n\nUtilisation d’une ACP non normée\nComme cela a été expliqué dans la première partie de ce chapitre, on préfère généralement utiliser des ACP normées lorsque l’on utilise des variables à unité de mesure hétérogènes. Mais dans l’exemple présent, toutes les variables sont exprimées dans la même unité et la question est plutôt de savoir quel poids on souhaite donner aux différentes variables. En réalisant une ACP normée, nous avons choisi de donner le même poids aux 5 variables dans la constitution des axes, alors même que nous avons vu que chacune d’elle a une moyenne et une variance différente. Nous aurions donc pu effectuer une ACP non normée en modifiant très légèrement notre programme, ce qui aurait donné un avantage plus grand aux variables à forte variance telles que la consommation de viande ou de céréales.\n\nmonACP3<-PCA(don3,scale.unit = F, ind.sup = 10, quanti.sup = 7)\n\n\n\n\n\n\nsummary(monACP3)\n\n\nCall:\nPCA(X = don3, scale.unit = F, ind.sup = 10, quanti.sup = 7) \n\n\nEigenvalues\n                          Dim.1      Dim.2      Dim.3      Dim.4      Dim.5\nVariance             219511.477 134291.136   9558.400   6419.145   2307.939\n% of var.                58.978     36.081      2.568      1.725      0.620\nCumulative % of var.     58.978     95.058     97.627     99.351     99.971\n                          Dim.6\nVariance                106.768\n% of var.                 0.029\nCumulative % of var.    100.000\n\nIndividuals\n                 Dist      Dim.1      ctr     cos2      Dim.2      ctr     cos2\nAFR_Sud    |  400.967 |  -10.657    0.006    0.001 |  365.913   11.078    0.833\nAFR_Centre |  971.614 | -692.711   24.289    0.508 | -677.862   38.018    0.487\nAFR_Ouest  |  568.891 | -556.454   15.673    0.957 |  -14.692    0.018    0.001\nAFR_Est    |  485.160 | -423.650    9.085    0.763 |  108.689    0.977    0.050\nAFR_Nord   |  756.322 | -214.943    2.339    0.081 |  709.835   41.689    0.881\nEUR_Sud    |  442.475 |  382.292    7.398    0.746 | -129.633    1.390    0.086\nEUR_Ouest  |  708.067 |  660.606   22.089    0.870 | -245.955    5.005    0.121\nEUR_Est    |  366.670 |  350.891    6.232    0.916 |   29.246    0.071    0.006\nEUR_Nord   |  531.333 |  504.627   12.890    0.902 | -145.540    1.753    0.075\n                Dim.3      ctr     cos2  \nAFR_Sud    | -119.192   16.515    0.088 |\nAFR_Centre |   37.935    1.673    0.002 |\nAFR_Ouest  |   93.858   10.240    0.027 |\nAFR_Est    | -198.844   45.962    0.168 |\nAFR_Nord   |  141.401   23.242    0.035 |\nEUR_Sud    |   25.094    0.732    0.003 |\nEUR_Ouest  |   31.578    1.159    0.002 |\nEUR_Est    |    7.131    0.059    0.000 |\nEUR_Nord   |  -18.960    0.418    0.001 |\n\nSupplementary individual\n                 Dist      Dim.1     cos2      Dim.2     cos2      Dim.3\nBénin      |  654.549 | -588.586    0.809 | -185.740    0.081 |  154.831\n               cos2  \nBénin         0.056 |\n\nVariables\n                Dim.1      ctr     cos2      Dim.2      ctr     cos2      Dim.3\nAnimaux    |  399.425   72.680    0.970 |  -60.949    2.766    0.023 |   24.829\nCéréales   |  -41.020    0.767    0.017 |  308.834   71.024    0.959 |   46.018\nLégumes    | -186.285   15.809    0.468 | -184.153   25.253    0.458 |   72.116\nHuiles     |   98.008    4.376    0.594 |   -1.750    0.002    0.000 |   35.656\nSucres     |  104.281    4.954    0.809 |   33.853    0.853    0.085 |   18.749\nDivers     |   55.734    1.415    0.678 |  -11.674    0.101    0.030 |   -0.810\n                ctr     cos2  \nAnimaux       6.450    0.004 |\nCéréales     22.155    0.021 |\nLégumes      54.410    0.070 |\nHuiles       13.301    0.079 |\nSucres        3.678    0.026 |\nDivers        0.007    0.000 |\n\nSupplementary continuous variable\n               Dim.1    cos2     Dim.2    cos2     Dim.3    cos2  \nTOTAL      | 430.143   0.800 |  84.161   0.031 | 196.558   0.167 |\n\n\n\nCommentaire : En comparant les résultats de cette ACP non normée avec ceux de l’ACP normée, on voit que les axes factoriels sont désormais surtout déterminés par les trois variables qui avaient la plus forte variance à savoir les consommations de viande, de céréales et de légume. Les trois autres variables (consommations de sucre, huile et divers) jouent désormais un rôle beaucoup plus faible dans la constitution des axes. La position relative des individus n’est plus la même que précédemment ce qui est logique puisque les facteurs 1 et 2 sont de nature différente."
  }
]